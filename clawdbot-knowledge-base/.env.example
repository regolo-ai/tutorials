# ============================================================================
# Regolo API Configuration
# Get your API key at: https://regolo.ai/dashboard
# ============================================================================
REGOLO_API_KEY=sk-your-regolo-api-key-here
REGOLO_BASE_URL=https://api.regolo.ai/v1

# Models available on Regolo GPU (EU-hosted, OpenAI-compatible)
# See full list: https://regolo.ai/models-library/
EMBED_MODEL=gte-Qwen2              # Embeddings: €0.05/1M input tokens
RERANK_MODEL=Qwen3-Reranker-4B     # Reranking: €0.01/query
CHAT_MODEL=Llama-3.1-8B-Instruct   # Generation: €0.05 input, €0.25 output per 1M tokens

# Alternative models (uncomment to use):
# CHAT_MODEL=Llama-3.3-70B-Instruct  # Better quality, higher cost
# CHAT_MODEL=Qwen2.5-72B-Instruct    # Strong reasoning
# EMBED_MODEL=Qwen3-Embedding-8B     # Alternative embeddings

# ============================================================================
# Telegram Bot Configuration
# Create bot via @BotFather: https://t.me/botfather
# ============================================================================
TELEGRAM_BOT_TOKEN=1234567890:ABCdefGHIjklMNOpqrsTUVwxyz-example
TELEGRAM_CHAT_ID=123456789  # Your chat ID for admin notifications

# Get your chat ID: message your bot, then visit:
# https://api.telegram.org/bot<YOUR_BOT_TOKEN>/getUpdates

# ============================================================================
# Knowledge Base Configuration
# ============================================================================
KB_DOCS_PATH=./knowledge-base
KB_INDEX_PATH=./index

# Auto-update configuration
KB_AUTO_UPDATE_ENABLED=true
KB_AUTO_UPDATE_CRON=0 2 * * *  # Daily at 2 AM (cron format)

# Supported formats: .txt, .md, .pdf
# Add your documents to ./knowledge-base/ folder

# ============================================================================
# Performance & Cost Controls
# ============================================================================
MAX_QUERIES_PER_DAY=500        # Daily rate limit per user
MAX_CHUNKS_RETRIEVE=20         # Hybrid search candidates (more = better recall, higher cost)
MAX_CHUNKS_RERANK=5           # Final context chunks for LLM (more = better quality, higher cost)
CHUNK_SIZE=600                # Tokens per chunk (400-800 recommended)
CHUNK_OVERLAP=100             # Overlap between chunks (preserves context)

# Cost optimization tips:
# - Lower MAX_CHUNKS_RETRIEVE to 10 for faster responses
# - Use Llama-3.1-8B-Instruct instead of 70B for 5x cost savings
# - Increase CHUNK_SIZE to 800 for fewer chunks (lower embedding cost)

# ============================================================================
# Logging & Monitoring
# ============================================================================
LOG_LEVEL=INFO                 # DEBUG, INFO, WARNING, ERROR
LOG_FILE=./logs/kb-bot.log
METRICS_ENABLED=true           # Track usage statistics and costs

# ============================================================================
# Optional: Slack Integration (alternative to Telegram)
# ============================================================================
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
# SLACK_BOT_TOKEN=xoxb-your-slack-bot-token

# ============================================================================
# Optional: Advanced Features
# ============================================================================
# ENABLE_CACHE=true            # Cache frequent queries (requires Redis)
# REDIS_URL=redis://localhost:6379
# CACHE_TTL_SECONDS=3600       # 1 hour
